# Incident Commander â€” Sistema Multi-Agente para InvestigaciÃ³n de Incidentes

Sistema multi-agente que simula la respuesta a incidentes de producciÃ³n. Recibe alertas, investiga problemas usando herramientas especializadas, y genera diagnÃ³sticos con reportes escritos a disco.

**Demo principal del workshop "Fundamentos de IngenierÃ­a de IA" - SesiÃ³n de Agentes IA.**

## Â¿QuÃ© EnseÃ±a Este Demo?

| Concepto | CÃ³mo se ve en el demo |
|----------|----------------------|
| **QuÃ© es un agente** | El Commander recibe un objetivo ("investigar el incidente") y decide autÃ³nomamente cÃ³mo resolverlo |
| **Function calling / Tools** | Cada investigaciÃ³n usa funciones concretas: `check_service_status()`, `search_logs()`, etc. |
| **MCP Tools** | El postmortem_agent escribe reportes a disco usando un servidor MCP de filesystem â€” la tool no vive en el cÃ³digo del agente |
| **ReAct loop** | En los traces de `adk web`: Thought â†’ Action â†’ Observation â†’ Thought â†’ ... |
| **Multi-agent** | El Commander delega a 3 sub-agentes especializados |
| **Orchestrator-Workers** | El Commander decide dinÃ¡micamente quÃ© agente necesita y en quÃ© orden |
| **Multi-modelo** | ConfiguraciÃ³n centralizada permite cambiar entre diferentes modelos (OpenAI, Gemini) desde una variable de entorno |
| **ConfiguraciÃ³n centralizada** | Un solo archivo `models.py` gestiona la configuraciÃ³n del modelo para todos los agentes |

**Framework:** Google ADK (Agent Development Kit)  
**PatrÃ³n de arquitectura:** Orchestrator-Workers con LLM-based orchestration  
**Modelos:** Configurable via `.env` (por defecto: gpt-5-nano para todos los agentes)

---

## Arquitectura

### PatrÃ³n: Orchestrator-Workers

El Incident Commander implementa el patrÃ³n **Orchestrator-Workers** de Anthropic. El orquestador (commander) usa su LLM para decidir dinÃ¡micamente a quÃ© worker (sub-agent) delegar y en quÃ© orden.

**Diferencia con Prompt Chaining:** El flujo natural del incidente tiende a ser secuencial (diagnosticar â†’ logs â†’ postmortem), pero la secuencia **no estÃ¡ hardcodeada** â€” el LLM decide. Con prompts vagos, puede cambiar el orden o volver a llamar a un agente.

### Diagramas de Arquitectura - Modelo C4

#### Nivel 1: Diagrama de Contexto

```mermaid
flowchart TD
    engineer["ğŸ‘¤ <b>Ingeniero de Soporte</b><br/><i>EnvÃ­a alertas de incidentes<br/>y recibe diagnÃ³sticos</i>"]

    incident_system["ğŸ¤– <b>Incident Commander System</b><br/><i>Sistema multi-agente que investiga<br/>incidentes de producciÃ³n<br/>usando Google ADK</i>"]

    llm_provider["â˜ï¸ <b>Proveedor LLM</b><br/><i>OpenAI / Gemini</i>"]
    mcp_server["ğŸ“ <b>MCP Filesystem Server</b><br/><i>Node.js / npx</i>"]
    prod_platform["ğŸ–¥ï¸ <b>Plataforma de ProducciÃ³n</b><br/><i>auth-service, api-gateway,<br/>payments-api</i>"]

    engineer -- "EnvÃ­a alertas y recibe diagnÃ³sticos<br/>(Chat / CLI / API REST)" --> incident_system
    incident_system -- "EnvÃ­a prompts y recibe respuestas<br/>(API HTTP)" --> llm_provider
    incident_system -- "Escribe reportes postmortem<br/>(MCP Protocol)" --> mcp_server
    incident_system -- "Consulta estado, mÃ©tricas y logs<br/>(Function Calling)" --> prod_platform

    style engineer fill:#08427b,color:#fff,stroke:#073b6f
    style incident_system fill:#1168bd,color:#fff,stroke:#0b4884
    style llm_provider fill:#999,color:#fff,stroke:#6b6b6b
    style mcp_server fill:#999,color:#fff,stroke:#6b6b6b
    style prod_platform fill:#999,color:#fff,stroke:#6b6b6b
```

#### Nivel 2: Diagrama de Contenedores

```mermaid
flowchart TD
    engineer["ğŸ‘¤ <b>Ingeniero de Soporte</b><br/><i>EnvÃ­a alertas de incidentes<br/>y recibe diagnÃ³sticos</i>"]

    subgraph incident_system ["ğŸ”² Incident Commander System"]
        adk_agent["ğŸ¤– <b>Incident Commander Agent</b><br/><i>Python / Google ADK</i><br/><i>1 orquestador + 3 workers</i>"]
        adk_ui["ğŸ–¥ï¸ <b>ADK Web UI / CLI</b><br/><i>Google ADK</i><br/><i>adk web / adk run</i>"]
        fastapi["ğŸŒ <b>FastAPI Custom Server</b><br/><i>Python / Uvicorn</i><br/><i>/health, /dev-ui, /docs</i>"]
    end

    llm_provider["â˜ï¸ <b>Proveedor LLM</b><br/><i>OpenAI / Gemini</i>"]
    mcp_server["ğŸ“ <b>MCP Filesystem Server</b><br/><i>Node.js / npx</i>"]
    prod_platform["ğŸ–¥ï¸ <b>Plataforma de ProducciÃ³n</b><br/><i>auth-service, api-gateway,<br/>payments-api</i>"]

    engineer -- "Chat / Terminal" --> adk_ui
    engineer -- "HTTP / REST" --> fastapi
    adk_ui -- "Usa" --> adk_agent
    fastapi -- "Usa" --> adk_agent
    adk_agent -- "Prompts y respuestas<br/>(API HTTP)" --> llm_provider
    adk_agent -- "Escribe reportes<br/>(MCP Protocol)" --> mcp_server
    adk_agent -- "Estado, mÃ©tricas y logs<br/>(Function Calling)" --> prod_platform

    style engineer fill:#08427b,color:#fff,stroke:#073b6f
    style adk_agent fill:#1168bd,color:#fff,stroke:#0b4884
    style adk_ui fill:#1168bd,color:#fff,stroke:#0b4884
    style fastapi fill:#1168bd,color:#fff,stroke:#0b4884
    style llm_provider fill:#999,color:#fff,stroke:#6b6b6b
    style mcp_server fill:#999,color:#fff,stroke:#6b6b6b
    style prod_platform fill:#999,color:#fff,stroke:#6b6b6b
    style incident_system fill:none,stroke:#1168bd,stroke-width:2px,stroke-dasharray:5 5
```

#### Nivel 3: Diagrama de Componentes â€” Incident Commander Agent

```mermaid
flowchart TD
    subgraph adk_agent ["ğŸ”² Incident Commander Agent"]
        commander["ğŸ–ï¸ <b>Incident Commander</b><br/><i>Python / Google ADK</i><br/><i>Orquestador</i>"]

        subgraph diagnostic_group [" "]
            diagnostic["ğŸ” <b>Diagnostic Agent</b><br/><i>Python / Google ADK</i><br/><i>LlmAgent - Worker</i>"]
            check_status["ğŸ”§ <b>check_service_status</b><br/><i>Componente: Python</i><br/><i>Verifica estado de un servicio<br/>(UP / DOWN / DEGRADED)</i>"]
            check_metrics["ğŸ”§ <b>check_metrics</b><br/><i>Componente: Python</i><br/><i>Consulta mÃ©tricas de CPU,<br/>memoria, conexiones DB y latencia</i>"]
        end

        subgraph logs_group [" "]
            logs["ğŸ“‹ <b>Logs Agent</b><br/><i>Python / Google ADK</i><br/><i>LlmAgent - Worker</i>"]
            search_logs["ğŸ”§ <b>search_logs</b><br/><i>Componente: Python</i><br/><i>Busca logs filtrados por<br/>severidad y ventana de tiempo</i>"]
        end

        subgraph postmortem_group [" "]
            postmortem["ğŸ“ <b>Postmortem Agent</b><br/><i>Python / Google ADK</i><br/><i>LlmAgent - Worker</i>"]
            get_runbook["ğŸ”§ <b>get_runbook</b><br/><i>Componente: Python</i><br/><i>Obtiene procedimientos estÃ¡ndar<br/>de remediaciÃ³n</i>"]
            write_file["ğŸ”§ <b>write_file</b><br/><i>Componente: MCP Tool</i><br/><i>Escribe reportes postmortem<br/>a disco</i>"]
        end
    end

    llm_provider["â˜ï¸ <b>Proveedor LLM</b><br/><i>OpenAI / Gemini</i>"]
    mcp_server["ğŸ“ <b>MCP Filesystem Server</b><br/><i>Node.js / npx</i>"]
    prod_platform["ğŸ–¥ï¸ <b>Plataforma de ProducciÃ³n</b><br/><i>auth-service, api-gateway,<br/>payments-api</i>"]

    commander -- "Delega diagnÃ³stico a subagente" --> diagnostic
    commander -- "Delega anÃ¡lisis de logs a subagente" --> logs
    commander -- "Delega reporte a subagente" --> postmortem
    commander -- "Usa para razonamiento" --> llm_provider

    diagnostic --> check_status
    diagnostic --> check_metrics
    check_status -- "Consulta estado" --> prod_platform
    check_metrics -- "Consulta mÃ©tricas" --> prod_platform

    logs --> search_logs
    search_logs -- "Consulta logs" --> prod_platform

    postmortem --> get_runbook
    postmortem --> write_file
    get_runbook -- "Consulta runbooks" --> prod_platform
    write_file -- "Escribe reportes" --> mcp_server

    style commander fill:#08427b,color:#fff,stroke:#073b6f
    style diagnostic fill:#1168bd,color:#fff,stroke:#0b4884
    style logs fill:#1168bd,color:#fff,stroke:#0b4884
    style postmortem fill:#1168bd,color:#fff,stroke:#0b4884
    style check_status fill:#85bbf0,color:#000,stroke:#5a9bd5
    style check_metrics fill:#85bbf0,color:#000,stroke:#5a9bd5
    style search_logs fill:#85bbf0,color:#000,stroke:#5a9bd5
    style get_runbook fill:#85bbf0,color:#000,stroke:#5a9bd5
    style write_file fill:#85bbf0,color:#000,stroke:#5a9bd5
    style llm_provider fill:#999,color:#fff,stroke:#6b6b6b
    style mcp_server fill:#999,color:#fff,stroke:#6b6b6b
    style prod_platform fill:#999,color:#fff,stroke:#6b6b6b
    style adk_agent fill:none,stroke:#1168bd,stroke-width:2px,stroke-dasharray:5 5
    style diagnostic_group fill:none,stroke:#1168bd,stroke-width:1px,stroke-dasharray:3 3
    style logs_group fill:none,stroke:#1168bd,stroke-width:1px,stroke-dasharray:3 3
    style postmortem_group fill:none,stroke:#1168bd,stroke-width:1px,stroke-dasharray:3 3
```

### Agentes

#### 1. **incident_commander** (Orquestador)
- **Modelo:** Configurable via `MODEL_NAME` (default: gpt-5-nano)
- **Rol:** Coordina la investigaciÃ³n del incidente
- **Sub-agentes:** diagnostic_agent, logs_agent, postmortem_agent
- **Protocolo:** TRIAGE â†’ CAUSA RAÃZ â†’ REPORTE â†’ RESUMEN

#### 2. **diagnostic_agent** (Worker)
- **Modelo:** Compartido desde `models.py`
- **Rol:** Especialista en verificar estado de servicios y mÃ©tricas
- **Tools:**
  - `check_service_status(service_name)` â€” Verifica estado (UP/DOWN/DEGRADED)
  - `check_metrics(service_name)` â€” Revisa CPU, memoria, conexiones DB, latencia

#### 3. **logs_agent** (Worker)
- **Modelo:** Compartido desde `models.py`
- **Rol:** Especialista en anÃ¡lisis de logs y patrones de error
- **Tools:**
  - `search_logs(service_name, severity, minutes)` â€” Busca logs filtrados por severidad y ventana de tiempo

#### 4. **postmortem_agent** (Worker)
- **Modelo:** Compartido desde `models.py`
- **Rol:** Especialista en generar reportes de postmortem estructurados
- **Tools:**
  - `get_runbook(issue_type)` â€” Obtiene procedimientos estÃ¡ndar (runbooks)
  - `write_file(path, content)` â€” Escribe reportes a disco (via MCP filesystem server)

---

## Requisitos Previos

- **Python 3.12+**
- **uv** instalado (gestor de paquetes Python moderno)
- **Node.js y npx** (para el MCP filesystem server)
- **API Keys:**
  - Google API Key (para Gemini)
  - OpenAI API Key (para GPT-5-nano)

---

## ConfiguraciÃ³n

### 1. Navegar al directorio raÃ­z de agentes

```bash
cd agents
```

### 2. Sincronizar dependencias con uv

```bash
uv sync
```

Esto instalarÃ¡ automÃ¡ticamente:
- `google-adk` - Framework para desarrollo de agentes
- `litellm` - Interfaz unificada para mÃºltiples LLM providers
- Dependencias del MCP server

### 3. Configurar variables de entorno

```bash
cp .env.example .env
```

Edita `.env` con tus API keys y configuraciÃ³n del modelo:

```env
# Model Configuration
MODEL_NAME=gpt-5-nano  # Opciones: gpt-5-nano, gpt-4o-mini, gpt-4o, gemini-2.0-flash, gemini-1.5-flash

# Google AI API Configuration
GOOGLE_GENAI_USE_VERTEXAI=FALSE
GOOGLE_API_KEY=tu-google-api-key-aqui

# OpenAI API Configuration (requerido si usas modelos GPT)
OPENAI_API_KEY=tu-openai-api-key-aqui
```

**Nota sobre modelos:**
- Modelos **OpenAI** (`gpt-*`): Requieren `OPENAI_API_KEY`, se configuran automÃ¡ticamente con LiteLLM
- Modelos **Gemini**: Requieren `GOOGLE_API_KEY`, se usan directamente
- Todos los agentes usan el mismo modelo configurado en `MODEL_NAME`

---

## Modos de EjecuciÃ³n

### OpciÃ³n 1: `adk web` (Recomendado para demos)

Interfaz web interactiva con visualizaciÃ³n de traces y eventos:

```bash
cd agents/incident_commander/
adk web
```

Abre el navegador en `http://localhost:8000` (o el puerto indicado). Desde allÃ­:
- EnvÃ­a mensajes al agente en el chat
- Ve los traces de cada delegaciÃ³n y tool call
- Observa el flujo ReAct en tiempo real

### OpciÃ³n 2: `adk run` (CLI interactivo)

```bash
cd agents/incident_commander/
adk run incident_commander
```

ConversaciÃ³n interactiva en la terminal.

### OpciÃ³n 3: `adk api_server` (API REST automÃ¡tica)

```bash
cd agents/incident_commander/
adk api_server
```

Levanta un servidor FastAPI con endpoints REST y WebSocket. API docs en `/docs`.

### OpciÃ³n 4: `uvicorn main:app` (FastAPI custom)

Servidor FastAPI personalizado con endpoints adicionales:

```bash
cd agents/incident-commander-system/incident_commander/
uvicorn main:app --reload --port 8000
```

Incluye:
- `/health` â€” Health check endpoint
- `/` â€” InformaciÃ³n del servicio
- `/dev-ui/` â€” Dev UI de ADK
- `/docs` â€” API documentation

---

## Ejemplos de Entrada para Demos

### 1. Alerta completa (Demo principal â€” muestra los 3 sub-agentes)

```
ALERTA CRÃTICA â€” P1

Servicio afectado: auth-service
Estado: DOWN
SÃ­ntoma: Usuarios no pueden hacer login desde las 3:00 PM
Error reportado: HTTP 503 en todos los endpoints de autenticaciÃ³n
Servicios posiblemente afectados: api-gateway

Por favor investiga el incidente, identifica la causa raÃ­z y genera un reporte de postmortem.
```

**QuÃ© demuestra:** Flujo completo del Orchestrator-Workers. El commander delega secuencialmente a los 3 agentes. Se ven todas las tools en acciÃ³n incluyendo el write_file del MCP.

### 2. Alerta vaga (Muestra razonamiento autÃ³nomo)

```
Alerta: Los usuarios estÃ¡n reportando que no pueden hacer login. Parece que algo se cayÃ³.
Investiga quÃ© estÃ¡ pasando.
```

**QuÃ© demuestra:** AutonomÃ­a del agente. No le dicen quÃ© servicio revisar ni en quÃ© orden â€” el commander debe decidir por su cuenta. En los traces se ve el razonamiento del LLM.

### 3. Health check rÃ¡pido (Demo parcial â€” solo diagnostic_agent)

```
Necesito un health check rÃ¡pido de los 3 servicios: auth-service, api-gateway y payments-api.
Dame el estado y las mÃ©tricas de cada uno.
```

**QuÃ© demuestra:** El commander delega solo al diagnostic_agent. Se ven 6 tool calls. Ãštil para demos cortos.

### 4. Solo anÃ¡lisis de logs (Muestra delegaciÃ³n especÃ­fica)

```
Revisa los logs de auth-service de los Ãºltimos 30 minutos. Necesito entender
quÃ© pasÃ³ y cuÃ¡ndo empezÃ³ el problema.
```

**QuÃ© demuestra:** El commander delega solo al logs_agent. Muestra delegaciÃ³n selectiva basada en la tarea.

### 5. Pregunta de seguimiento (DespuÃ©s de entrada 1 o 2)

```
Â¿CuÃ¡l es el impacto actual en los usuarios finales? Â¿payments-api estÃ¡ en riesgo?
```

**QuÃ© demuestra:** El agente mantiene contexto de la conversaciÃ³n. Muestra memory/session en ADK.

---

## Estructura del Proyecto

```
incident_commander/
â”œâ”€â”€ __init__.py                  # ConvenciÃ³n ADK: from . import agent
â”œâ”€â”€ agent.py                     # Entry point: root_agent = incident_commander
â”œâ”€â”€ models.py                    # ConfiguraciÃ³n centralizada del modelo
â”œâ”€â”€ prompts.py                   # Prompts del orquestador
â”œâ”€â”€ main.py                      # FastAPI custom (opcional)
â”œâ”€â”€ .env.example                 # Plantilla de configuraciÃ³n
â”œâ”€â”€ .gitignore                   # reports/, .env, __pycache__/, .adk/
â”œâ”€â”€ reports/                     # Reportes generados por MCP
â”‚   â””â”€â”€ .gitkeep                 # Mantiene el directorio en git
â””â”€â”€ sub_agents/                  # Workers especializados
    â”œâ”€â”€ diagnostic_agent/
    â”‚   â”œâ”€â”€ __init__.py          # from . import agent
    â”‚   â”œâ”€â”€ agent.py             # Define diagnostic_agent
    â”‚   â”œâ”€â”€ prompts.py           # Prompts del agente
    â”‚   â””â”€â”€ tools.py             # Tools: check_service_status, check_metrics
    â”œâ”€â”€ logs_agent/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ agent.py             # Define logs_agent
    â”‚   â”œâ”€â”€ prompts.py           # Prompts del agente
    â”‚   â””â”€â”€ tools.py             # Tools: search_logs
    â””â”€â”€ postmortem_agent/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ agent.py             # Define postmortem_agent (con MCP)
        â”œâ”€â”€ prompts.py           # Prompts del agente
        â””â”€â”€ tools.py             # Tools: get_runbook
```

**Notas de arquitectura:**
- **`models.py`**: Un solo archivo gestiona la configuraciÃ³n del modelo para todos los agentes
- **Imports absolutos**: Los sub-agentes importan con `from incident_commander.models import MODEL`
- **Estructura plana**: Archivos `prompts.py` y `tools.py` en lugar de subdirectorios
- **`sub_agents/`**: Directorio siguiendo la convenciÃ³n de Google ADK (evita conflictos con auto-discovery)

---

## Mock Data

El sistema usa **datos simulados inline** en las tools (no archivos externos):

- **Servicios:** auth-service (DOWN), api-gateway (DEGRADED), payments-api (HEALTHY)
- **Incidente simulado:** Agotamiento del pool de conexiones de BD tras deploy v2.4.1
- **Timeline:** Deploy a las 14:25 â†’ Falla a las 14:58 â†’ "Tiempo actual" simulado: 15:05 (2025-06-15)
- **Causa raÃ­z:** Query `SELECT * FROM sessions WHERE expired=false` no cierra conexiones

---

## Recursos Adicionales

- **Google ADK Docs:** [https://google.github.io/adk-docs/](https://google.github.io/adk-docs/)
- **Anthropic Agent Patterns:** [https://www.anthropic.com/research/building-effective-agents](https://www.anthropic.com/research/building-effective-agents)
- **MCP Documentation:** [https://modelcontextprotocol.io/](https://modelcontextprotocol.io/)
- **Design Document:** `.specs/features/agents/incident-commander/design.md` (en la raÃ­z del repo)

---

## Licencia

Proyecto educativo para el workshop "Fundamentos de IngenierÃ­a de IA".
